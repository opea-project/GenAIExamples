# Inference API Configuration
# INFERENCE_API_ENDPOINT: URL to your inference service (without /v1 suffix)
#   - For GenAI Gateway: https://genai-gateway.example.com
#   - For APISIX Gateway: https://apisix-gateway.example.com/inference
#
# INFERENCE_API_TOKEN: Authentication token/API key for the inference service
#   - For GenAI Gateway: Your GenAI Gateway API key
#   - For APISIX Gateway: Your APISIX authentication token
INFERENCE_API_ENDPOINT=https://your-api-endpoint.com/deployment
INFERENCE_API_TOKEN=your-pre-generated-token-here
INFERENCE_MODEL_NAME=deepseek-ai/DeepSeek-R1-Distill-Qwen-32B

# Service Configuration
SERVICE_PORT=8002

# Model Settings
DEFAULT_TONE=conversational
DEFAULT_MAX_LENGTH=2000

# Generation Parameters
TEMPERATURE=0.7
MAX_TOKENS=4000
MAX_RETRIES=3
