# Video RAG

## Introduction
Visual RAG is a framework that retrives video based on provided user prompt. It uses both video scene description generated by open source vision models (ex video-llama, video-llava etc.) as text embeddings and frames as image embeddings to perform vector similarity search. The provided solution also supports feature to retrieve more similar videos without prompting it. (see the example video below)

![Example Video](docs/visual-rag-demo.gif)

## Tools

- **UI**: streamlit
- **Vector Storage**: Chroma DB **or** Intel's VDMS
- **Image Embeddings**: CLIP
- **Text Embeddings**: all-MiniLM-L12-v2
- **RAG Retriever**: Langchain Ensemble Retrieval

## Prerequisites

There are 10 example videos present in ```video_ingest/videos``` along with their description generated by open-source vision model.
If you want these visual RAG to work on your own videos, make sure it matches below format.

## File Structure

```bash
video_ingest/
.
└── videos
    ├── op_10_0320241830.mp4
    ├── op_1_0320241830.mp4
    ├── op_19_0320241830.mp4
    ├── op_21_0320241830.mp4
    ├── op_24_0320241830.mp4
    ├── op_31_0320241830.mp4
    ├── op_47_0320241830.mp4
    ├── op_5_0320241915.mp4
    ├── op_DSCF2862_Rendered_001.mp4
    └── op_DSCF2864_Rendered_006.mp4
```

## Setup and Installation

Install pip requirements

```bash
cd VideoRAGQnA
conda create --name vrag python=3.9 && conda activate vrag
pip install -r docs/requirements.txt
```

This code is using a pre-released update of vdms vectordb in LangChain.
```bash
cd cw-langchain-vdms-patch/libs/community
pip install -e .
cd ../../../
```

Download Llama-2-7b-chat-hf and video-llama models

```bash
mkdir -p embedding/video_llama_weights
cd embedding/video_llama_weights
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/VL_LLaMA_2_7B_Finetuned.pth

cd ../../
mkdir -p meta-llama/Llama-2-7b-chat-hf
cd meta-llama/Llama-2-7b-chat-hf
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/config.json
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/generation_config.json
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/pytorch_model-00001-of-00002.bin
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/pytorch_model-00002-of-00002.bin
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/pytorch_model.bin.index.json
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/special_tokens_map.json
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/tokenizer.json
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/tokenizer.model
wget https://huggingface.co/DAMO-NLP-SG/Video-LLaMA-2-7B-Finetuned/resolve/main/llama-2-7b-chat-hf/tokenizer_config.json
cd ../..
```


The current framework supports both Chroma DB and Intel's VDMS.
We tested using VDMS only after video embedding based modification.

Running Chroma DB as docker container
```bash
docker run -d -p 8000:8000 chromadb/chroma
```
**Troubleshooting:** If using chromadb, and getting this error ```ValueError: Could not connect to tenant default_tenant```, then: 
```bash
export no_proxy="0.0.0.0"
```
**or**

Running VDMS DB as docker container
```bash
docker run -d -p 55555:55555 intellabs/vdms:latest
```

**Note-1:** If you are not using file structure similar to what is described above, consider changing it in ```docs/config.yaml```.

**Note-2:** Update your choice of db and port in ```docs/config.yaml```.


**Web UI Video RAG**
```bash
streamlit run video-rag-ui.py docs/config.yaml --server.address 0.0.0.0 --server.port 50055
```

