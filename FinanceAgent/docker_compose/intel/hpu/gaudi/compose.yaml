# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

services:  
  # docsum-vllm-gaudi:
  #   image: opea/llm-docsum:latest
  #   container_name: docsum-vllm-gaudi
  #   ports:
  #     - ${DOCSUM_PORT:-9000}:9000
  #   ipc: host
  #   environment:
  #     no_proxy: ${no_proxy}
  #     http_proxy: ${http_proxy}
  #     https_proxy: ${https_proxy}
  #     LLM_ENDPOINT: ${LLM_ENDPOINT}
  #     LLM_MODEL_ID: ${LLM_MODEL_ID}
  #     HF_TOKEN: ${HF_TOKEN}
  #     LOGFLAG: ${LOGFLAG:-False}
  #     MAX_INPUT_TOKENS: ${MAX_INPUT_TOKENS}
  #     MAX_TOTAL_TOKENS: ${MAX_TOTAL_TOKENS}
  #     DocSum_COMPONENT_NAME: ${DocSum_COMPONENT_NAME:-OpeaDocSumvLLM}
  #   restart: unless-stopped

  worker-sum-agent:
    image: opea/agent:latest
    container_name: sum-agent-endpoint
    # depends_on:
    #   - docsum-vllm-gaudi
    volumes:
      - ${TOOLSET_PATH}:/home/user/tools/
      - ${PROMPT_PATH}:/home/user/prompts/
    ports:
      - "9097:9097"
    ipc: host
    environment:
      ip_address: ${ip_address}
      strategy: react_llama
      with_memory: false
      recursion_limit: ${recursion_limit_worker}
      llm_engine: vllm
      HUGGINGFACEHUB_API_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}
      llm_endpoint_url: ${LLM_ENDPOINT_URL}
      model: ${LLM_MODEL_ID}
      temperature: ${TEMPERATURE}
      max_new_tokens: ${MAX_TOKENS}
      stream: false
      tools: /home/user/tools/sum_agent_tools.yaml
      custom_prompt: /home/user/prompts/sum_prompt.py
      require_human_feedback: false
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      REDIS_URL_VECTOR: $REDIS_URL_VECTOR
      REDIS_URL_KV: $REDIS_URL_KV
      TEI_EMBEDDING_ENDPOINT: $TEI_EMBEDDING_ENDPOINT
      DOCSUM_ENDPOINT: $DOCSUM_ENDPOINT
      port: 9097
